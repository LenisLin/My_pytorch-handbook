{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch Basic 4：数据的加载和预处理.ipynb","provenance":[],"authorship_tag":"ABX9TyPdqDkTc2smKwojAx798v7t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"C98GEigXrAUk"},"source":["# 挂载到云端硬盘，使得可以读入下载数据"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BjcXX8a9qwVM","executionInfo":{"status":"ok","timestamp":1637132002900,"user_tz":-480,"elapsed":34799,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"b220016e-6167-4bd5-fc6e-c7ff09735b2a"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive\"\n","\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['pytorch-handbook']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Gt4-zNu5ma77"},"source":["# PyTorch 基础 :数据的加载和预处理\n","PyTorch通过`torch.utils.data`对一般常用的`数据加载`进行了封装，可以很容易地实现`多线程数据预读`和`批量加载`。\n","\n","并且`torchvision`已经预先实现了`常用图像数据集`，包括前面使用过的CIFAR-10，ImageNet、COCO、MNIST、LSUN等数据集，可通过`torchvision.datasets`方便的调用"]},{"cell_type":"code","metadata":{"id":"pxKQZ9qJ7AfR","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1637130907343,"user_tz":-480,"elapsed":27732,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"4a1c0af3-123a-4d3e-ce6e-72ed5388ea0a"},"source":["# 首先要引入相关的包\n","import torch\n","#打印一下版本\n","torch.__version__"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.10.0+cu111'"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"J1IJvvqjm54t"},"source":["## Dataset\n","Dataset是一个抽象类，为了能够方便的读取，需要`将要使用的数据包装为Dataset类`。\n","自定义的Dataset需要继承它并且实现两个成员方法：\n","1. `__getitem__()` 该方法定义用索引(`0` 到 `len(self)`)获取一条数据或一个样本，`__getitem__()`可以使我们通过索引来找到一个实例\n","\n","2. `__len__()` 该方法返回数据集的总长度\n","\n","PS：不要忘了应该要初始化这个类的属性，`def __init__`\n","\n","下面我们使用kaggle上的一个竞赛[bluebook for bulldozers](https://www.kaggle.com/c/bluebook-for-bulldozers/data)自定义一个数据集，为了方便介绍，我们使用里面的数据字典来做说明（因为条数少）"]},{"cell_type":"code","metadata":{"id":"MtcEPNTunOa7","executionInfo":{"status":"ok","timestamp":1637131028194,"user_tz":-480,"elapsed":461,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}}},"source":["#引用\n","from torch.utils.data import Dataset\n","import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vrYbWwQnSGJ","executionInfo":{"status":"ok","timestamp":1637131373695,"user_tz":-480,"elapsed":414,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}}},"source":["## 定义一个数据集\n","class BulldozerDataset(Dataset):\n","  ## BulldozerDataset类继承Dataset\n","  def __init__(self,csv_file):\n","    ## 初试化数据集类，属性为一个csv文件\n","    self.df=pd.read_csv(csv_file)\n","\n","  def __len__(self):\n","    ## __len__是要计算数据集的总长度\n","    return len(self.df)\n","  \n","  def __getitem__(self,idx):\n","    ## __getitem__帮助我们通过索引来返回一个实例\n","    return self.df.iloc[idx].SalePrice ## 这里可能不需要用 .iloc方法也可以，因为直接用Index来索引\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-MdR3pJofUG"},"source":["至此，我们的数据集已经定义完成了，我们可以实例化一个对象访问他"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2bQa980ojLj","executionInfo":{"status":"ok","timestamp":1637132246887,"user_tz":-480,"elapsed":460,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"c7f06edf-dd8e-40bd-a11a-68ab8af62db6"},"source":["print(os.listdir())\n","ds_demo= BulldozerDataset('/content/drive/MyDrive/pytorch-handbook/chapter2(pytorch basic)/median_benchmark.csv') ## 方法，右边那个文件夹显示，然后去最上面找路径"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["['pytorch-handbook']\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ea_-5O_8sRJr"},"source":["尝试用一下我们之前定义的`__len__()`和`__getitem__()`方法"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ianfftnsXhR","executionInfo":{"status":"ok","timestamp":1637132474045,"user_tz":-480,"elapsed":426,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"9f86db6a-44e1-43f8-ff78-11f479495407"},"source":["print(ds_demo.__len__()) ## 尝试使用 .__len__()方法\n","print(ds_demo[0]) ## .__getitem__()帮助我们通过索引你来访问一个实例，很类似 .iloc[某行,]"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["11573\n","24000.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"b2IJtyzhsy1p"},"source":["自定义的数据集已经创建好了，下面我们使用官方提供的数据载入器，读取数据\n","## Dataloader\n","`DataLoader`为我们提供了`对Dataset的读取操作`，可以说,`DataLoader`专门用来读取`Dataset`\n","\n","常用参数有：\n","\n","- batch_size(每个batch的大小)\n","\n","- shuffle(是否进行shuffle操作)\n","\n","- num_workers(加载数据的时候使用几个子进程)。\n","\n","下面做一个简单的操作："]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bqXSeDCtEli","executionInfo":{"status":"ok","timestamp":1637132658720,"user_tz":-480,"elapsed":392,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"2799acb2-7b93-4aeb-d8ca-2cf9c882a476"},"source":["dl=torch.utils.data.DataLoader(ds_demo,batch_size=10,shuffle=True,num_workers=10)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"markdown","metadata":{"id":"on_J5siltjnT"},"source":["`DataLoader`返回的是一个可迭代对象，我们可以使用迭代器分次获取数据。即，DataLoader相当于帮我们缓读了数据，并且做了分batch，shuffle等操作。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OlZrwJzntX4G","executionInfo":{"status":"ok","timestamp":1637132757538,"user_tz":-480,"elapsed":809,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"1d1bb96e-a9f4-4200-841d-a075f4be8f46"},"source":["idata=iter(dl) ## 获得其中一个batch\n","print(idata.__len__()) ## 其中一个batch的长度\n","print(next(idata)) ## next batch"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["1158\n","tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.,\n","        24000.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ExPdZC5gw_PL"},"source":["常见的用法是使用`for循环`对其进行遍历"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-j9sxTxyE_l","executionInfo":{"status":"ok","timestamp":1637133997711,"user_tz":-480,"elapsed":856,"user":{"displayName":"Yuxiang Lin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10241123578442902660"}},"outputId":"2bbe9940-f5fd-447b-80ea-a348b7250294"},"source":["for i, data in enumerate(dl): ## enumerate针对一个可以迭代的对象，dl是之前定义的Dataload对象，是个迭代器，其中每一个对象都是一个batch\n","    print(i,data) ## 打印这个batch\n","    # 为了节约空间，这里只循环一遍\n","    break"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["0 tensor([24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000., 24000.,\n","        24000.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"sKObqm0tzChk"},"source":["我们已经可以通过`dataset定义数据集`，并使用`Datalorder载入`和遍历数据集，除了这些以外，PyTorch还提供能torcvision的计算机视觉扩展包\n","## torchvision \n","`torchvision` 是PyTorch中专门用来`处理图像`的库，PyTorch官网的安装教程中最后的pip install torchvision 就是安装这个包。"]},{"cell_type":"markdown","metadata":{"id":"zuEaqNJ_zQXB"},"source":["### torchvision.datasets\n","torchvision.datasets 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用：\n","- MNIST\n","- COCO\n","- Captions\n","- Detection\n","- LSUN\n","- ImageFolder\n","- Imagenet-12\n","- CIFAR\n","- STL10\n","- SVHN\n","- PhotoTour\n","\n","我们可以直接使用，示例如下："]},{"cell_type":"code","metadata":{"id":"1rJzOjxczUXS"},"source":["import torchvision.datasets as datasets\n","trainset = datasets.MNIST(root='./data', # 表示MNIST数据的加载的目录\n","                                      train=True,  # 表示是否加载数据库的训练集，false的时候加载测试集\n","                                      download=True, # 表示是否自动下载 MNIST 数据集\n","                                      transform=None) # 表示是否需要对数据进行预处理，none为不进行预处理\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GKCwmFf6zfOK"},"source":["### torchvision.models\n","torchvision不仅提供了常用图片数据集，还提供了`训练好`的模型，可以加载之后，直接使用，或者在进行`迁移学习`\n","\n","`torchvision.models`模块的 子模块中包含以下模型结构。\n","- AlexNet\n","- VGG\n","- ResNet\n","- SqueezeNet\n","- DenseNet\n","\n","就类似torch.nn.Module里面有fully-connected layer，CONV layer一样。\n"]},{"cell_type":"code","metadata":{"id":"RICuGH2Pz-Ge"},"source":["#我们直接可以使用训练好的模型，当然这个与datasets相同，都是需要从服务器下载的\n","import torchvision.models as models\n","resnet18 = models.resnet18(pretrained=True) ## pretrained，预训练好的"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KE5pf-_x0FRr"},"source":["### torchvision.transforms\n","`transforms`模块提供了一般的图像转换操作类，用作`数据处理`和`数据增强`"]},{"cell_type":"code","metadata":{"id":"b6rnSGzm0Rtl"},"source":["from torchvision import transforms as transforms\n","transform = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),  #先四周填充0，在把图像随机裁剪成32*32\n","    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n","    transforms.RandomRotation((-45,45)), #随机旋转\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQDpfeYG0XtK"},"source":["肯定有人会问：(0.485, 0.456, 0.406), (0.2023, 0.1994, 0.2010) 这几个数字是什么意思？\n","\n","图像每个像素都有RGB值，0-225，构成一个彩色图像，三个通道，如果只有一个通道那么就是一个灰度图像。对于每个channel进行归一化需要一个均值和方差，上面那两个三元组对应了每一个通道的均值和方差，具体为什么是这些参数看下面那个链接\n","\n","官方的这个帖子有详细的说明:\n","https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/21\n","\n","这些都是根据ImageNet训练的归一化参数，可以直接使用，我们认为这个是固定值就可以"]}]}